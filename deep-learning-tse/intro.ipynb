{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yet another practical introduction to deep learning\n",
    "\n",
    "## Generalities\n",
    "\n",
    "### Max Halford\n",
    "\n",
    "#### Toulouse School of Economics Master's degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Information\n",
    "\n",
    "- We have a lot to cover\n",
    "- Please ask questions\n",
    "- The slides are available [here](https://github.com/MaxHalford/data-science-tutorials)\n",
    "- For this part of the course, you'll be graded by having to write a short essay\n",
    "- All the learning material you need (for free!):\n",
    "    1. [Stanford CS230 Deep Learning -- Andrew Ng and Kian Katanforoosh](https://cs231n.github.io/)\n",
    "    2. [The Deep Learning textbook -- Ian Goodfellow, Yoshua Bengio and Aaron Courville](http://www.deeplearningbook.org/)\n",
    "    3. [Deep Learning with Python -- Francois Chollet](http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.4\n",
      "IPython 7.4.0\n",
      "\n",
      "keras 2.2.4\n",
      "tensorflow 1.14.0\n",
      "sklearn 0.21.3\n",
      "matplotlib 3.0.3\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.2.10-arch1-1-ARCH\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/max/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -m -v -p keras,tensorflow,sklearn,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is deep learning?\n",
    "\n",
    "- Subcase of machine learning, which is itself a subcase of artificial intelligence\n",
    "- Artificial intelligence is about understanding concepts\n",
    "- Machine learning is about learning concepts through example\n",
    "- Deep learning is a specific machine learning method which works (very) well in some cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The fit/predict paradigm\n",
    "\n",
    "Our goal is to learn from a set of training examples `(X_train, y_train)` and to predict the (unknown) outcome of a test set `X_test`.\n",
    "\n",
    "    X_train, y_train, X_test = split(dataset)\n",
    "    \n",
    "`X_train` and `X_test` are the inputs, they can be images, text, tabular data, graphs... `y_train` is the output, it can be a real number, a class, multiple numbers, multiple classes... As we will see deep learning is very flexible, and a lot of cases can be handled.\n",
    "\n",
    "We \"train\" (or \"fit\", it's the same meaning) a model by showing it examples.\n",
    "\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "We \"predict\" by running test examples through the model and getting outputs.\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "Note that `X_train`, `X_test`, and `y_train` can be stored in memory, or can be streamed from the disk (more about this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating performance\n",
    "\n",
    "Knowing how well a model performs is very important. To do so, we can:\n",
    "\n",
    "1. Split the training set in two:\n",
    "    1. (`X_fit`, `y_fit`), the learning set\n",
    "    2. (`X_val`, `y_val`), the validation set\n",
    "2. Train the model on (`X_fit`, `y_fit`)\n",
    "3. Obtain predictions `y_pred` for `X_val`\n",
    "4. Calculate the error by comparing `y_pred` and `y_val`\n",
    "\n",
    "We thus look at the performance of the model on unseen data. Indeed, our goal is to have a model that generalizes well. This is very important. \n",
    "\n",
    "We can repeat the above process many times with random subsets and average the error scores. This is called [cross-validation](https://www.wikiwand.com/en/Cross-validation_(statistics)) and is very important in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A simple example: MNIST digits classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)  # Takes a bit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70000 images\n",
      "Each image is composed of 784 pixels\n"
     ]
    }
   ],
   "source": [
    "n_images, n_pixels = X.shape\n",
    "\n",
    "print(f'There are {n_images} images')\n",
    "print(f'Each image is composed of {n_pixels} pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode the labels because that's the only to do multi-class classification with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import utils\n",
    "\n",
    "y_one_hot = utils.to_categorical(y, num_classes=10)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's the split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y):\n",
    "    return (\n",
    "        X[:60000],  # X_train is the first 60.000 images\n",
    "        X[-10000:],  # X_test is the last 10.000 images\n",
    "        y[:60000],  # y_train is the first 60.000 labels\n",
    "        y[-10000:]  # y_test is the last 10.000 images\n",
    "    )\n",
    "\n",
    "X_fit, X_val, y_fit, y_val = split(X, y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = utils.normalize(X_fit)\n",
    "X_val = utils.normalize(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1104 11:51:43.829179 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1104 11:51:43.842388 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1104 11:51:43.844791 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1104 11:51:43.873245 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1104 11:51:43.893444 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),  # 784 is the number of pixels in each image\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the model on the learning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1104 11:51:44.105311 140205977196352 deprecation.py:323] From /home/max/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1104 11:51:44.171396 140205977196352 deprecation_wrapper.py:119] From /home/max/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.4909 - acc: 0.8803\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2507 - acc: 0.9274\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.2014 - acc: 0.9412\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.1706 - acc: 0.9503\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1493 - acc: 0.9564\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_fit, y_fit, epochs=5, batch_size=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on validation set is 0.9568\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "\n",
    "y_val_labels = y_val.argmax(axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_val_labels, y_pred_labels)\n",
    "print(f'Accuracy score on validation set is {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation score is similar to the training score, which is a good sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.2242 - acc: 0.9324\n",
      "Epoch 2/20\n",
      "49120/60000 [=======================>......] - ETA: 4s - loss: 0.0942 - acc: 0.9716"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78d1fb1b243b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_fit, y_fit, epochs=20, batch_size=32);\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "y_val_labels = y_val.argmax(axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_val_labels, y_pred_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras\n",
    "\n",
    "- High-level Python library for building and training neural networks\n",
    "- Started in March 2015\n",
    "- Abstracts a lot of complexity\n",
    "- Doesn't do any compute, it's simply an abstraction on top of Tensorflow/Theano\n",
    "- Very clean API interface\n",
    "- Encourages you to think in terms of modules\n",
    "- PyTorch is the main rival, both have their pros and cons\n",
    "- [Documentation](https://keras.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reminder about backpropagation\n",
    "\n",
    "1. Your network is nothing more than a set of weights $w_i$\n",
    "2. You have an input $x_i$ and a known output $y_i$\n",
    "3. The network processes your input and produces an estimated output $\\hat{y}_i$\n",
    "4. You can calculate by how much the network is wrong by using a loss function $L(y_i, \\hat{y}_i)$\n",
    "5. The loss function if differentiable, and so we can we obtain the gradient $g_i$ with respect to each weight\n",
    "6. We can then modify each weight by using the gradient\n",
    "\n",
    "Backpropagation is the mechanism which will calculate the gradient $g_i$. If you're not interested in how it works, you can treat it as a blackbox and come back to it later on. Check out [this great demo](https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent\n",
    "\n",
    "1. When we call `fit`, the neural network goes through each example in the dataset\n",
    "2. For each observation $(x_i, y_i)$, the gradient $\\nabla_i$ is obtained\n",
    "3. An optimizer takes care of obtaining the new weights $w_{i+1}$ by modifying the current weights $w_i$ and using the current gradient $\\nabla_i$\n",
    "4. We can loop multiple times through the dataset; each iteration is called an **epoch**\n",
    "\n",
    "A general formulation of stochastic gradient descent (SGD):\n",
    "\n",
    "$$w_{i+1} \\leftarrow f(w_i, \\nabla_i, \\eta_i)$$\n",
    "\n",
    "$\\eta_i$ is the learning rate at iteration $i$, it's *extremely* important and we'll come back to it very soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss function\n",
    "\n",
    "The list of loss functions implemented in Keras is available [here](https://keras.io/losses/). You can set the loss function via the `loss` parameter of the `compile` method.\n",
    "\n",
    "There are many loss functions to choose. Choosing one mostly depends on what you're trying to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "\n",
    "# MSE loss\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer='sgd'\n",
    ")\n",
    "\n",
    "# Same thing\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='sgd'\n",
    ")\n",
    "\n",
    "# Same thing\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer='sgd'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "Used for general purpose regression. Penalizes large mistakes.\n",
    "\n",
    "$$L(y, \\hat{y}) = (y - \\hat{y}) ^ 2$$\n",
    "\n",
    "**Logistic loss**\n",
    "\n",
    "The most common loss used for classification. For binary classification Keras calls it `binary_crossentropy` whereas for multi-class classification it calls it `categorical_crossentropy`.\n",
    "\n",
    "$$L(y, p) = log(1 + exp(-yp))$$\n",
    "\n",
    "**Poisson loss**\n",
    "\n",
    "Used for estimating counts (arrivals in an airport, number of call events to call center, etc.), which is a specific case of regression.\n",
    "\n",
    "$$L(y, \\hat{y}) = \\hat{y} - y \\times log(\\hat{y})$$\n",
    "\n",
    "**Hinge loss**\n",
    "\n",
    "$$L(y, p) = max(1, 1 - yp)$$\n",
    "\n",
    "Loss functions have a big impact on the learning algorithm. For instance the only difference between linear regression and logistic regression is that linear regression is a linear model with a squared loss whereas logistic regression is a linear model with a logistic loss.\n",
    "\n",
    "There are many more loss functions that you can use in machine learning. You can even design your own! For example the deep learning community introduced the [focal loss](https://arxiv.org/abs/1708.02002) to deal with imbalanced datasets. Vowpal Wabbit also [designed](https://arxiv.org/abs/1011.1576) a set of loss functions that support importance weights. [Here](https://keras.io/losses/) is the documentation for Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batching\n",
    "\n",
    "At each iteration $i$, instead of updating the weights $w_i$ by using the gradient $g_i$, we can accumulate the gradients and only update the weights every $k$ iterations.\n",
    "\n",
    "The gradient we will use to update the weights will thus be the average of the past $k$ gradients. This is called **mini-batch gradient descent**. Stochastic gradient descent can be seen as a special case of mini-batch gradient descent when the batch size is set to 1.\n",
    "\n",
    "![mini-batch](mini-batch.png)\n",
    "\n",
    "In Keras, the batch size is set when calling the `fit` method:\n",
    "\n",
    "```python\n",
    "model.fit(X_fit, y_fit, epochs=20, batch_size=32)\n",
    "```\n",
    "\n",
    "The batch size is important. Small batch size work well because they are a form of regula\n",
    "\n",
    "Here are some links if you want to get some intuitions:\n",
    "\n",
    "- [Tradeoff batch size vs. number of iterations to train a neural network - Cross Validated](https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network)\n",
    "- [What is batch size in neural network? - Cross Validated](https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network)\n",
    "- [In deep learning, why don't we use the whole training set to compute the gradient? - Quora](https://www.quora.com/In-deep-learning-why-dont-we-use-the-whole-training-set-to-compute-the-gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input normalization\n",
    "\n",
    "When you're doing gradient descent, the scale of the features matters a lot. Indeed the magnitudes of the gradient descent steps are influenced by the absolute values of the features. If the features are too large, then the gradient steps might be too large and the model will diverge.\n",
    "\n",
    "**Always scale your data**\n",
    "\n",
    "99% of the time, it is recommended to scale your data so that each feature has mean 0 and standard deviation 1. See [this](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html) for a deeper explanation.\n",
    " \n",
    "You can use scikit-learn's `scale` method from the `preprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.StandardScaler().fit_transform(X)\n",
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "In the previous slide we just mentionned the word **regularization**, what is it exactly?\n",
    "\n",
    "1. A machine learning model learns from a training set \n",
    "2. We want the model to perform well on a test set it hasn't seen\n",
    "3. The stronger the model, the more there is a chance that it overfits by memorizing patterns that only exists in the training set\n",
    "4. Regularizing a model means that we make it's life harder  \n",
    "5. There are many ways to regularize a neural network:\n",
    "    1. Use more data! The more training data there is, the more the model will focus on general patterns\n",
    "    2. Penalize the updates made to the weights by the optimizer \n",
    "    3. Use dropout\n",
    "    4. Use batch normalization\n",
    "    5. Use early stopping\n",
    "    \n",
    "![complexity](complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "The list of available optimizers is available [here](https://keras.io/optimizers/). A good overview of the optimizers commonly used in deep learning is available [here](https://ruder.io/optimizing-gradient-descent/index.html).\n",
    "\n",
    "**Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "$$w_{i+1} = w_{i} - \\eta_i \\nabla_i $$\n",
    "\n",
    "**Momentum**\n",
    "\n",
    "The idea is to accumulate the past gradients in order to not lose any acceleration. This can help from getting stuck into a local optima.\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{split}\n",
    "v_{i+1} = \\gamma v_{i} + \\eta_i \\nabla_i \\\\\n",
    "w_{i+1} = w_{i} - v_{i+1}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "**AdaGrad**\n",
    "\n",
    "$$ w_{i+1} = w_{i} - \\frac{\\eta_i}{\\sqrt{G_t + \\epsilon}} \\times g_{i}  $$\n",
    "\n",
    "where $G_t$ is a diagonal matrix where each diagonal term is the sum of the squares of the past gradients. This has the effect of dampening the updates of the weights of frequently occurring features.\n",
    "\n",
    "You can combine tricks: Adam is just Momentum + AdaDelta.\n",
    "\n",
    "Read [Sebastian Ruder's](https://ruder.io/optimizing-gradient-descent/index.html) blog post for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=optimizers.SGD(lr=0.01, momentum=0.9),\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning rate\n",
    "\n",
    "- The learning rate determines the amplitude of a weight update step.\n",
    "- From Sebastian Ruder: \"*Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge.*\"\n",
    "- Learning rate schedulers exist, but they are defined independently from the characteristics of the dataset.\n",
    "- LÃ©on Bottou [proposed](https://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf) an adaptive learning rate, but is not implemented in Keras\n",
    "\n",
    "![learning-rate](learning-rate.png)\n",
    "\n",
    "In Keras we specify the learning rate via the `optimizer` we choose.\n",
    "\n",
    "A common misconception is that Keras uses a constant learning rate. It doesn't. It has the following update schedule:\n",
    "\n",
    "```python\n",
    "learning_rate = learning_rate * 1 / (1 + decay * epoch)\n",
    "```\n",
    "\n",
    "where `decay` is a parameter given to the `optimizer` and `epoch` is the current epoch number.\n",
    "\n",
    "You can override the learning rate by using the [`LearningRateScheduler` callback](https://keras.io/callbacks/#learningratescheduler).\n",
    "\n",
    "You can also use the [`ReduceLROnPlateau` callback](https://keras.io/callbacks/#reducelronplateau) to modify the learning rate when a metric has stopped improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f83e7db6650>,\n",
       " <keras.layers.core.Dense at 0x7f83e330a150>,\n",
       " <keras.layers.core.Dense at 0x7f83e330a350>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3_input:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Relu:0' shape=(?, 512) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Relu:0' shape=(?, 512) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a deep dive into [Keras' documentation on layers](https://keras.io/layers/about-keras-layers/) as it is excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weight initialization\n",
    "\n",
    "Initializing the weights of a neural network might seem like a detail, but it helps when the network is quite large. In Keras, you can choose an initializer for each layer:\n",
    "\n",
    "```python\n",
    "network = models.Sequential([\n",
    "    layers.Dense(\n",
    "        units=16,\n",
    "        input_shape=(number_of_features,),\n",
    "        kernel_initializer='random_uniform',\n",
    "        bias_initializer='zeros'\n",
    "    ),\n",
    "    layers.Dense(units=16, kernel_initializer='glorot_normal'),\n",
    "    layers.Dense(units=1, bias_initializer='he_normal')\n",
    "])\n",
    "```\n",
    "\n",
    "[Here](https://keras.io/initializers/) is the Keras documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics\n",
    "\n",
    "A metric measures the performance of a learning algorithm. It is different from a loss function, which is used to obtain gradients. Ideally, if we want to optimize a metric, we would want to use the metric as a loss function. Alas, not all metrics are differentiable. However, some loss functions act as good *proxies*. For instance, if your aim is to optimize accuracy, then using a Hinge loss might be a good idea.\n",
    "\n",
    "For regression, we typically measure the [mean squared error (MSE)](https://www.wikiwand.com/en/Mean_squared_error). You can directly use the mean squared error as a loss function. The same goes for the root mean squared error (RMSE).\n",
    "\n",
    "Measuring the [mean absolute error (MAE)](https://www.wikiwand.com/en/Mean_absolute_error) is also quite common as it makes a lot of sense for humans. In this case, using the mean squared error is suboptimal. The [Cauchy loss function](https://www.kaggle.com/c/allstate-claims-severity/discussion/24520#140163) might work better.\n",
    "\n",
    "For classification you have many choices and it mostly depends on your application. Accuracy is typically a poor metric choice as it doesn't translate a business need. If you're interested in lowering false positives, then measure the precision. If you don't want false negatives, then measure the recall. If you want a mix of both then measure the F1-score. If you're only interested in getting a good ranking (such as for anomaly detection), then measure the AUC. The [Wikipedia page](https://www.wikiwand.com/en/Precision_and_recall) on precision and recall is quite information. In any case, you'll probably do fine by using the standard logarithmic loss. If your dataset is unbalanced or you really don't want false positives, then try out the [focal loss](https://arxiv.org/abs/1708.02002) or use sample weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural way to choose the number of epochs is to monitor the performance of the network on a validation at each epoch. When the score on the validation set goes down, then we can stop.\n",
    "\n",
    "We'll use an example from [this](https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Save np.load\n",
    "np_load_old = np.load\n",
    "# Modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "# Call load_data with allow_pickle implicitly set to true\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
    "# Restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# SAME THING\n",
    "\n",
    "network = models.Sequential([\n",
    "    layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)),\n",
    "    layers.Dense(units=16, activation='relu'),\n",
    "    layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = network.fit(\n",
    "    train_features, \n",
    "    train_target, \n",
    "    epochs=20, \n",
    "    verbose=0, \n",
    "    batch_size=100, \n",
    "    validation_data=(test_features, test_target)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the train and test performance for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 1s 56us/step - loss: 0.0960 - acc: 0.9691 - val_loss: 0.6513 - val_acc: 0.8330\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 0.0871 - acc: 0.9729 - val_loss: 0.6690 - val_acc: 0.8309\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 0.0794 - acc: 0.9760 - val_loss: 0.7140 - val_acc: 0.8291\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2),\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = network.fit(\n",
    "    train_features, \n",
    "    train_target, \n",
    "    epochs=20, \n",
    "    verbose=1, \n",
    "    batch_size=100, \n",
    "    validation_data=(test_features, test_target),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,333,770\n",
      "Trainable params: 1,333,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=(784,)),\n",
    "    layers.Dropout(rate=0.2),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(rate=0.4),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 803840 == 784 * 1024 + 1024\n",
    "assert 524800 == 1024 * 512 + 512\n",
    "assert 5130 == 512 * 10 + 10\n",
    "assert 803840 + 524800 + 5130 == 1333770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 133.00 410.00\" width=\"133pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 129,-406 129,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140204094372880 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140204094372880</title>\n",
       "<polygon fill=\"none\" points=\"8,-292.5 8,-328.5 117,-328.5 117,-292.5 8,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-306.8\">dense_35: Dense</text>\n",
       "</g>\n",
       "<!-- 140204178903888 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140204178903888</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 125,-255.5 125,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 140204094372880&#45;&gt;140204178903888 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140204094372880-&gt;140204178903888</title>\n",
       "<path d=\"M62.5,-292.4551C62.5,-284.3828 62.5,-274.6764 62.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"66.0001,-265.5903 62.5,-255.5904 59.0001,-265.5904 66.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140204178903632 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140204178903632</title>\n",
       "<polygon fill=\"none\" points=\"8,-146.5 8,-182.5 117,-182.5 117,-146.5 8,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">dense_36: Dense</text>\n",
       "</g>\n",
       "<!-- 140204178903888&#45;&gt;140204178903632 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140204178903888-&gt;140204178903632</title>\n",
       "<path d=\"M62.5,-219.4551C62.5,-211.3828 62.5,-201.6764 62.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"66.0001,-192.5903 62.5,-182.5904 59.0001,-192.5904 66.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140204178904464 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140204178904464</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 125,-109.5 125,-73.5 0,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-87.8\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 140204178903632&#45;&gt;140204178904464 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140204178903632-&gt;140204178904464</title>\n",
       "<path d=\"M62.5,-146.4551C62.5,-138.3828 62.5,-128.6764 62.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"66.0001,-119.5903 62.5,-109.5904 59.0001,-119.5904 66.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140204178904208 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140204178904208</title>\n",
       "<polygon fill=\"none\" points=\"8,-.5 8,-36.5 117,-36.5 117,-.5 8,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-14.8\">dense_37: Dense</text>\n",
       "</g>\n",
       "<!-- 140204178904464&#45;&gt;140204178904208 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140204178904464-&gt;140204178904208</title>\n",
       "<path d=\"M62.5,-73.4551C62.5,-65.3828 62.5,-55.6764 62.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"66.0001,-46.5903 62.5,-36.5904 59.0001,-46.5904 66.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140204178905168 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140204178905168</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-365.5 3.5,-401.5 121.5,-401.5 121.5,-365.5 3.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-379.8\">140204178905168</text>\n",
       "</g>\n",
       "<!-- 140204178905168&#45;&gt;140204094372880 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140204178905168-&gt;140204094372880</title>\n",
       "<path d=\"M62.5,-365.4551C62.5,-357.3828 62.5,-347.6764 62.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"66.0001,-338.5903 62.5,-328.5904 59.0001,-338.5904 66.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cross-val](cross-val.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, #fit: 404, #val: 102, score: 68.421\n",
      "Fold 1, #fit: 405, #val: 101, score: 184.450\n",
      "Fold 2, #fit: 405, #val: 101, score: 93.986\n",
      "Fold 3, #fit: 405, #val: 101, score: 225.780\n",
      "Fold 4, #fit: 405, #val: 101, score: 65.500\n",
      "Global score: 127.627 (Â± 65.360)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "cross_val = model_selection.KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores = np.zeros(cross_val.n_splits)\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cross_val.split(X, y)):\n",
    "    \n",
    "    X_fit = X[fit_idx]\n",
    "    X_val = X[val_idx]\n",
    "    y_fit = y[fit_idx]\n",
    "    y_val = y[val_idx]\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(n_features,)),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_fit, y_fit, epochs=5, verbose=0, batch_size=8)\n",
    "    \n",
    "    # Make out-of-fold predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Store the score for this splits\n",
    "    scores[i] = metrics.mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    print(f'Fold {i}, #fit: {len(fit_idx)}, #val: {len(val_idx)}, score: {scores[i]:.3f}')\n",
    "    \n",
    "print(f'Global score: {scores.mean():.3f} (Â± {scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a heavy process and so it is not often done in practice. You'll more often see people using a training set and a test set (also called **holdout set**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at the Keras methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Configures the model for training.\n",
       "\n",
       "# Arguments\n",
       "    optimizer: String (name of optimizer) or optimizer instance.\n",
       "        See [optimizers](/optimizers).\n",
       "    loss: String (name of objective function) or objective function.\n",
       "        See [losses](/losses).\n",
       "        If the model has multiple outputs, you can use a different loss\n",
       "        on each output by passing a dictionary or a list of losses.\n",
       "        The loss value that will be minimized by the model\n",
       "        will then be the sum of all individual losses.\n",
       "    metrics: List of metrics to be evaluated by the model\n",
       "        during training and testing.\n",
       "        Typically you will use `metrics=['accuracy']`.\n",
       "        To specify different metrics for different outputs of a\n",
       "        multi-output model, you could also pass a dictionary,\n",
       "        such as `metrics={'output_a': 'accuracy'}`.\n",
       "    loss_weights: Optional list or dictionary specifying scalar\n",
       "        coefficients (Python floats) to weight the loss contributions\n",
       "        of different model outputs.\n",
       "        The loss value that will be minimized by the model\n",
       "        will then be the *weighted sum* of all individual losses,\n",
       "        weighted by the `loss_weights` coefficients.\n",
       "        If a list, it is expected to have a 1:1 mapping\n",
       "        to the model's outputs. If a tensor, it is expected to map\n",
       "        output names (strings) to scalar coefficients.\n",
       "    sample_weight_mode: If you need to do timestep-wise\n",
       "        sample weighting (2D weights), set this to `\"temporal\"`.\n",
       "        `None` defaults to sample-wise weights (1D).\n",
       "        If the model has multiple outputs, you can use a different\n",
       "        `sample_weight_mode` on each output by passing a\n",
       "        dictionary or a list of modes.\n",
       "    weighted_metrics: List of metrics to be evaluated and weighted\n",
       "        by sample_weight or class_weight during training and testing.\n",
       "    target_tensors: By default, Keras will create placeholders for the\n",
       "        model's target, which will be fed with the target data during\n",
       "        training. If instead you would like to use your own\n",
       "        target tensors (in turn, Keras will not expect external\n",
       "        Numpy data for these targets at training time), you\n",
       "        can specify them via the `target_tensors` argument. It can be\n",
       "        a single tensor (for a single-output model), a list of tensors,\n",
       "        or a dict mapping output names to target tensors.\n",
       "    **kwargs: When using the Theano/CNTK backends, these arguments\n",
       "        are passed into `K.function`.\n",
       "        When using the TensorFlow backend,\n",
       "        these arguments are passed into `tf.Session.run`.\n",
       "\n",
       "# Raises\n",
       "    ValueError: In case of invalid arguments for\n",
       "        `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model.compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I choose an architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many choices you can make that it can quickly become overwhelming. Choosing the right pieces of the puzzle is very much an art rather than a science. There is no getting around trying things out. It is thus very important to setup a stable environment for testing and evaluating model choices. You should always start by defining a reliable testing procedure.\n",
    "\n",
    "Here is some general advice:\n",
    "\n",
    "1. Start with a very simple model (for example a logistic regression)\n",
    "2. Add complexity to the model as long as the validation score improves\n",
    "3. If the model is overfitting (you can detect it by comparing the training and validation scores) then add regularization\n",
    "4. Last but not least, spend most of your time checking that the data you're using is correct\n",
    "\n",
    "Here are some more links if you're interested:\n",
    "\n",
    "- [How to decide neural network architecture? - Data Science exchange](https://datascience.stackexchange.com/questions/20222/how-to-decide-neural-network-architecture)\n",
    "- [How to choose the number of hidden layers and nodes in a feedforward neural network? - Cross Validated](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pretrained architecture\n",
    "\n",
    "To do!\n",
    "\n",
    "It's quite common to retrain an existing neural network for a particular task. We call this [transfer learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/). It is very much used for image and text classification. Check out [this page](https://keras.io/applications/) to see what networks Keras puts at your disposal.\n",
    "\n",
    "Let's first load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "y_one_hot = utils.to_categorical(y, num_classes=10)\n",
    "\n",
    "def split(X, y):\n",
    "    return (\n",
    "        X[:60000],  # X_train is the first 60.000 images\n",
    "        X[-10000:],  # X_test is the last 10.000 images\n",
    "        y[:60000],  # y_train is the first 60.000 labels\n",
    "        y[-10000:]  # y_test is the last 10.000 images\n",
    "    )\n",
    "\n",
    "X_fit, X_val, y_fit, y_val = split(X, y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fine-tune a VGG16 pretrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n",
       "        247., 127.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n",
       "        154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n",
       "        195.,  64.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n",
       "        253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n",
       "         39.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n",
       "        253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n",
       "        253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n",
       "        154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
       "        114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n",
       "        253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "        253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n",
       "        244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n",
       "         16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(28, 28, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-6ea0c83d76a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load a pretrained VGG16 without the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvgg16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Add a fully-connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 316\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    317\u001b[0m                 if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    318\u001b[0m                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(28, 28, 1)`"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Load a pretrained VGG16 without the last layer\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(28, 28, 1))\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = layers.Dense(128, activation='relu')(vgg16.output)\n",
    "\n",
    "# And a softmax layer\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "\n",
    "# We only want to train the layers we added\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done *after* setting layers to non-trainable\n",
    "model.compile(\n",
    "    loss=losses.binary_crossentropy,\n",
    "    optimizer=optimizers.Adam(),\n",
    "    metrics=[metrics.binary_accuracy],\n",
    ")\n",
    "\n",
    "# Train the model on the new data for a few epochs\n",
    "model.fit(X_fit, y_fit, epochs=5, batch_size=32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_5 to have 4 dimensions, but got array with shape (60000, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-f12fce81287c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have 4 dimensions, but got array with shape (60000, 784)"
     ]
    }
   ],
   "source": [
    "model.fit(X_fit, y_fit, epochs=5, batch_size=32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, None, None, 128)   65664     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, None, None, 10)    1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
